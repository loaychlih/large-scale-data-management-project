# Large Scale Data Management Project: Benchmark de Performance du PageRank

## Description du Projet

Ce projet a pour objectif d'√©valuer les performances de l'algorithme PageRank impl√©ment√© sur les DataFrames et les RDD (Resilient Distributed Datasets) sur Google Cloud Platform (GCP).

## Membres du groupe : 

- Loay Chlih ( ATAL)
- Mohammed Hmitouch (ATAL)

## Ressources Fournies

- **Cr√©dit de 50 $ par personne** sur Google Cloud Platform pour configurer et utiliser les clusters.

## Processus de Benchmarking

Tous les scripts utilis√©s pour les benchmarks sont situ√©s dans le r√©pertoire `scripts`.

Chaque dossier contient des scripts Bash pour cr√©er un cluster et ex√©cuter l'algorithme PageRank, sp√©cifiques aux technologies test√©es :

- `runrdd.sh` : Ex√©cute PageRank avec RDD (en utilisant `pagerankrdd.py`).
- `rundata.sh` : Ex√©cute PageRank avec DataFrame (en utilisant `pagerankdataframe.py`).

## Configurations des Clusters

Pour cette exp√©rience, plusieurs configurations de clusters ont √©t√© utilis√©es, chacune avec le m√™me mat√©riel CPU/RAM par n≈ìud pour assurer la comparabilit√© des r√©sultats :

### 1. Cluster √† 1 n≈ìud

- **Type de machine** : `n1-standard-4`
- **vCPUs** : 4
- **M√©moire** : 15 Go
- **Disque persistant** : 500 Go
- **SSD local** : Oui
- **Image** : `2.0-debian10`
- **Zone** : `europe-west1-c`

### 2. Cluster √† 2 n≈ìuds

- **Type de machine** : `n1-standard-4` (identique √† la configuration √† 1 n≈ìud)
- **vCPUs** : 4 par n≈ìud
- **M√©moire** : 15 Go par n≈ìud
- **Disque persistant** : 500 Go par n≈ìud
- **SSD local** : Oui
- **Image** : `2.0-debian10`
- **Zone** : `europe-west1-c`

### 3. Cluster √† 4 n≈ìuds

- **Type de machine** : `n1-standard-4` (identique √† la configuration √† 1 et 2 n≈ìuds)
- **vCPUs** : 4 par n≈ìud
- **M√©moire** : 15 Go par n≈ìud
- **Disque persistant** : 500 Go par n≈ìud
- **SSD local** : Oui
- **Image** : `2.0-debian10`
- **Zone** : `europe-west1-c`

## R√©sultats

### R√©sultats du Benchmark de small_page_links.nt : 

Les benchmarks ont √©t√© r√©alis√©s en variant le nombre de travailleurs, comme d√©taill√© ci-dessous :

#### RDD

| Nombre de Travailleurs | Temps RDD avec partitionnement | Temps RDD sans partitionnement |
| ---------------------- | ------------------------------ | ------------------------------------ |
| 1                      | 44.99299740791321 s             | 45.278162717819214 s                     |
| 2                      | 37.06561207771301 s          | 37.021756649017334 s                       |
| 4                      | 36.382244348526 s           | 36.139880895614624 s                     |

#### DataFrame

| Nombre de Travailleurs | Temps DataFrame avec partitionnement | Temps DataFrame sans partitionnement |
| ---------------------- | ----------------------------------- | ------------------------------------- |
| 1                      | 35.75928416307245 s             |     38.97059342108653                   |
| 2                      |   30.59381746290831 s                |   32.61837294508192                 |
| 4                      |    28.40967285139752 s               |     30.78420531967284                 |

#### Entit√© avec le plus grand page rank : 
L'entit√© avec le plus grand PageRank est üèÖ <http://dbpedia.org/resource/Attention-deficit_hyperactivity_disorder>' 0.30051150556157313

![TOP10](https://github.com/user-attachments/assets/dfc054e5-b0db-4ef9-a394-62b9716954bc)
#### RDD

| Nombre de Travailleurs | Temps RDD avec partitionnement | Temps RDD sans partitionnement |
| ---------------------- | ------------------------------ | ------------------------------------ |
| 1                      | 44.99299740791321 s             | 45.278162717819214 s                     |
| 2                      | 37.06561207771301 s          | 37.021756649017334 s                       |
| 4                      | 36.382244348526 s           | 36.139880895614624 s                     |

#### DataFrame

| Nombre de Travailleurs | Temps DataFrame avec partitionnement | Temps DataFrame sans partitionnement |
| ---------------------- | ----------------------------------- | ------------------------------------- |
| 1                      |  s             |                        |
| 2                      |    s                |                    |
| 4                      |     s               |                      |

#### Entit√© avec le plus grand page rank : 
L'entit√© avec le plus grand PageRank est üèÖ : <http://dbpedia.org/resource/Living_people> ' 36794.33146754483

![TOP10KBIR](https://github.com/user-attachments/assets/1af4b92c-d947-437a-9bc6-53579fc70b1f)

### R√©sultats du Benchmark de page_links_en.nt.bz2 :


## Instructions de Configuration

Pour ex√©cuter les benchmarks, suivez ces √©tapes :

1. **Configurez un cluster** en utilisant les scripts Bash fournis pour chaque technologie. Par exemple :
    - Pour **RDD** : Ex√©cutez `./runrdd.sh` en remplacant les donnees par small_page_links.nt
    - Pour **Dataframe** : Ex√©cutez `./rundata.sh`en remplacant les donnees par small_page_links.nt

2. **Modifiez le nombre de travailleurs dans les fichiers .sh**

Assurez-vous que votre compte Google Cloud est configur√© et que vous disposez des autorisations n√©cessaires pour lancer des clusters Dataproc.

## Conclusion
